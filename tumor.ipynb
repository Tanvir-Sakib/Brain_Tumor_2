{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Processed images saved in: data/processed_image\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_images(input_dir, output_dir, clip_limit=2.0, tile_grid_size=(8, 8), sigma=0.33, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Preprocess images using CLAHE and an improved Canny edge detection method for brain MRI tumor detection.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the input directory containing images.\n",
    "        output_dir (str): Path to the output directory for processed images.\n",
    "        clip_limit (float): Contrast limiting for CLAHE.\n",
    "        tile_grid_size (tuple): Size of the tiles for CLAHE.\n",
    "        sigma (float): Factor for calculating adaptive thresholds in Canny.\n",
    "        kernel_size (int): Size of Gaussian blur kernel to smooth the image.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        relative_path = os.path.relpath(root, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, relative_path)\n",
    "        if not os.path.exists(output_subdir):\n",
    "            os.makedirs(output_subdir)\n",
    "\n",
    "        for img_name in files:\n",
    "            try:\n",
    "                img_path = os.path.join(root, img_name)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Skipped: {img_path} (not a valid image)\")\n",
    "                    continue\n",
    "\n",
    "                # Apply CLAHE for contrast enhancement\n",
    "                img_clahe = clahe.apply(img)\n",
    "\n",
    "                # Apply Gaussian Blur to reduce noise\n",
    "                img_blur = cv2.GaussianBlur(img_clahe, (kernel_size, kernel_size), 0)\n",
    "\n",
    "                # Compute median and derive adaptive thresholds\n",
    "                v = int(np.median(img_blur))\n",
    "                lower = max(0, int((1.0 - sigma) * v))\n",
    "                upper = min(255, int((1.0 + sigma) * v))\n",
    "\n",
    "                # Apply Canny edge detection\n",
    "                img_canny = cv2.Canny(img_blur, lower, upper)\n",
    "\n",
    "                # Apply morphological closing to remove small gaps and noise\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                img_canny = cv2.morphologyEx(img_canny, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "                # Save the processed image\n",
    "                output_path = os.path.join(output_subdir, img_name)\n",
    "                cv2.imwrite(output_path, img_canny)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "    print(f\"Processing complete. Processed images saved in: {output_dir}\")\n",
    "\n",
    "# Example usage:\n",
    "preprocess_images(\"data/raw_images\", \"data/processed_image\", clip_limit=2.0, tile_grid_size=(8, 8), sigma=0.95, kernel_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [1/10], Loss: 0.5012\n",
      "Validation Loss: 0.3603, Accuracy: 85.34%\n",
      "Epoch [2/10], Loss: 0.2742\n",
      "Validation Loss: 0.2474, Accuracy: 90.09%\n",
      "Epoch [3/10], Loss: 0.1750\n",
      "Validation Loss: 0.1656, Accuracy: 94.18%\n",
      "Epoch [4/10], Loss: 0.1117\n",
      "Validation Loss: 0.1090, Accuracy: 98.17%\n",
      "Epoch [5/10], Loss: 0.0614\n",
      "Validation Loss: 0.0719, Accuracy: 98.92%\n",
      "Epoch [6/10], Loss: 0.0358\n",
      "Validation Loss: 0.0528, Accuracy: 99.35%\n",
      "Epoch [7/10], Loss: 0.0241\n",
      "Validation Loss: 0.0402, Accuracy: 99.35%\n",
      "Epoch [8/10], Loss: 0.0174\n",
      "Validation Loss: 0.0327, Accuracy: 99.57%\n",
      "Epoch [9/10], Loss: 0.0116\n",
      "Validation Loss: 0.0305, Accuracy: 99.35%\n",
      "Epoch [10/10], Loss: 0.0090\n",
      "Validation Loss: 0.0284, Accuracy: 99.35%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset class for multiple directories\n",
    "class MultiFolderBrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_dirs, labels, transform=None):\n",
    "        self.image_dirs = image_dirs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = None\n",
    "        for image_dir in self.image_dirs:\n",
    "            potential_path = os.path.join(image_dir, self.labels[idx]['image'])\n",
    "            if os.path.exists(potential_path):\n",
    "                img_path = potential_path\n",
    "                break\n",
    "\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"Image {self.labels[idx]['image']} not found in directories {self.image_dirs}\")\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Function to generate labels from multiple directories\n",
    "def generate_labels_multiple_dirs(image_dirs):\n",
    "    labels = []\n",
    "    for label, folder in enumerate(['yes', 'no']):\n",
    "        for image_dir in image_dirs:\n",
    "            folder_path = os.path.join(image_dir, folder)\n",
    "            if not os.path.exists(folder_path):\n",
    "                continue\n",
    "            for img_name in os.listdir(folder_path):\n",
    "                labels.append({'image': os.path.join(folder, img_name), 'label': label})\n",
    "    return labels\n",
    "\n",
    "# Grad-CAM class\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_full_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def generate_heatmap(self, gradients, activations):\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        activations = activations[0]  # Batch size is 1\n",
    "        for i in range(activations.shape[0]):\n",
    "            activations[i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "        heatmap = torch.mean(activations, dim=0).cpu().detach().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "        return heatmap\n",
    "\n",
    "    def __call__(self, input_tensor, class_idx=None):\n",
    "        self.model.eval()\n",
    "        with torch.enable_grad():  # Ensure gradients are enabled\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "            if class_idx is None:\n",
    "                class_idx = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            class_score = output[:, class_idx]\n",
    "            class_score.backward(retain_graph=True)\n",
    "\n",
    "            heatmap = self.generate_heatmap(self.gradients, self.activations)\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "# Save Grad-CAM images\n",
    "def save_gradcam_images(gradcam, input_tensor, original_image_paths, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i in range(input_tensor.size(0)):\n",
    "        heatmap = gradcam(input_tensor[i:i + 1])\n",
    "\n",
    "        # Load original image for overlay\n",
    "        original_image = cv2.imread(original_image_paths[i])\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize heatmap to original image size\n",
    "        heatmap_resized = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n",
    "        heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "        heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Overlay heatmap on the original image\n",
    "        overlayed_image = cv2.addWeighted(original_image, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "        # Save overlayed image\n",
    "        output_path = os.path.join(output_folder, f\"gradcam_{i}.jpg\")\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(overlayed_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Dataset setup\n",
    "processed_image_dir = 'data/processed_image'\n",
    "raw_image_dir = 'data/raw_images'\n",
    "image_dirs = [processed_image_dir, raw_image_dir]\n",
    "\n",
    "# Generate labels and split dataset\n",
    "labels = generate_labels_multiple_dirs(image_dirs)\n",
    "train_labels, val_labels = train_test_split(labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MultiFolderBrainTumorDataset(image_dirs, train_labels, transform)\n",
    "val_dataset = MultiFolderBrainTumorDataset(image_dirs, val_labels, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model setup\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: tumor (1) and no tumor (0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Grad-CAM setup\n",
    "gradcam = GradCAM(model, model.layer4)\n",
    "gradcam_output_dir = \"gradcam_output\"\n",
    "\n",
    "# Training loop with Grad-CAM during validation\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward and backward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(val_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Save Grad-CAM images\n",
    "            image_paths = [os.path.join(image_dirs[0], label['image']) for label in val_labels[idx * 64:(idx + 1) * 64]]\n",
    "            save_gradcam_images(gradcam, images, image_paths, gradcam_output_dir)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'brain_tumor_model_processed.pth'.\n",
      "Prediction for 47 no.jpg: No Tumor\n",
      "Prediction for 48 no.jpeg: No Tumor\n",
      "Prediction for 49 no.jpg: No Tumor\n",
      "Prediction for 50 no.jpg: No Tumor\n",
      "Prediction for no 100.jpg: No Tumor\n",
      "Prediction for no 99.jpg: No Tumor\n",
      "Prediction for no.jpg: No Tumor\n",
      "Prediction for No18.jpg: No Tumor\n",
      "Prediction for No19.jpg: No Tumor\n",
      "Prediction for No20.jpg: No Tumor\n",
      "Prediction for Y164.JPG: No Tumor\n",
      "Prediction for Y165.JPG: No Tumor\n",
      "Prediction for Y169.jpg: Tumor\n",
      "Prediction for Y183.jpg: No Tumor\n",
      "Prediction for Y192.JPG: Tumor\n",
      "Prediction for Y243.JPG: No Tumor\n",
      "Prediction for Y244.JPG: Tumor\n",
      "Prediction for Y246.JPG: No Tumor\n",
      "Prediction for Y255.JPG: Tumor\n",
      "Prediction for Y258.JPG: No Tumor\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'brain_tumor_model_processed.pth')\n",
    "print(\"Model saved as 'brain_tumor_model_processed.pth'.\")\n",
    "\n",
    "# Inference with a sample image\n",
    "def predict_sample(image_path, model, transform, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted.item()\n",
    "\n",
    "# Load the trained model for inference\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)  # Make sure model is initialized\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Adjust the output layer if needed\n",
    "model.load_state_dict(torch.load('brain_tumor_model_processed.pth'))  # Load weights\n",
    "model = model.to(device)  # Move the model to the correct device\n",
    "\n",
    "# 2 classes: tumor (1) and no tumor (0)\n",
    "classes = ['Tumor', 'No Tumor']\n",
    "\n",
    "# Path to the 'sample' folder containing images\n",
    "sample_folder_path = 'sample'  # Update with the correct path to your folder\n",
    "\n",
    "# Get all image files from the folder\n",
    "image_files = [f for f in os.listdir(sample_folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# Iterate over each image file in the folder and make predictions\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(sample_folder_path, image_file)\n",
    "    prediction = predict_sample(image_path, model, transform, device)\n",
    "    print(f\"Prediction for {image_file}: {classes[prediction]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
